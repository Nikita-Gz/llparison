{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\venvs\\llparison\\venv\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:model_runner.py:No HF token env variable\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "from model_data_loader import DatabaseConnector\n",
    "from task import Task\n",
    "from task_type import TaskType\n",
    "from model_runner import ModelRunner\n",
    "\n",
    "try:\n",
    "  __file__\n",
    "except NameError:\n",
    "  __file__ = 'nofile'\n",
    "log = logging.getLogger(os.path.basename(__file__))\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model_data_loader.py:real_data_mode: False\n"
     ]
    }
   ],
   "source": [
    "db = DatabaseConnector(\n",
    "  testing_mode=True,\n",
    "  insert_testing_models=False,\n",
    "  data_to_insert_by_default={\n",
    "    'models': [\n",
    "      {\n",
    "        '_id': 'hf:bigscience:bloomz-1b1',\n",
    "        'owner': 'bigscience',\n",
    "        'name': 'bloomz-1b1',\n",
    "        'source': 'hf',\n",
    "        'first_tracked_on': str(datetime.datetime.now()),\n",
    "        'last_tracked_on': str(datetime.datetime.now()),\n",
    "        'tracking_history': [\n",
    "          {\n",
    "            'date': str(datetime.datetime.now()),\n",
    "            'hf_inference_api_supported': False,\n",
    "            'available': True,\n",
    "            'context_size': 2048,\n",
    "            'price_prompt': 0,\n",
    "            'price_completion': 0,\n",
    "            'prompt_limit': 1000,\n",
    "            'max_tokens_limit': 1000,\n",
    "            'discount': 0.0\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(TaskType.READING_COMPREHENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\model_running\\test_1.1b_model.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/NewDriveSync/MAGISTR/Diploma/llparison/model_running/test_1.1b_model.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(db\u001b[39m.\u001b[39;49mexperiments\u001b[39m.\u001b[39;49mfind())[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a = list(db.experiments.find())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = list(a['outputs'])\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:task.py:Running reading comprehension on date 2023-09-12 10:50:39.186509 with cost limit None\n",
      "INFO:task.py:Got 1 unfinished experiments for task Reading Comprehension from DB\n",
      "INFO:task.py:Returning experiment {'_id': 'Reading Comprehensionhf:bigscience:bloomz-1b1{\"temperature\": 0.01, \"top-p\": 0.5}2023-09-12 10:42:31.073524', 'date': '2023-09-12 10:42:31.073524', 'finished': False, 'too_expensive': False, 'model_id': 'hf:bigscience:bloomz-1b1', 'iterations': 1, 'config': {'temperature': 0.01, 'top-p': 0.5}, 'notes': '', 'task_type': 'Reading Comprehension', 'metrics': {}, 'outputs': [{'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10024.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10024.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10024.txt:2', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10042.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10042.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10042.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10042.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10042.txt:4', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10060.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10060.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10060.txt:2', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10112.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10112.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10112.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10146.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10146.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10146.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10154.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10154.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10154.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10160.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10160.txt:1', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10160.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10177.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10177.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10177.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10179.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10179.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10179.txt:2', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10179.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10187.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10187.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10187.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10215.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10215.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10215.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10229.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10229.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10229.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10255.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10255.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10255.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10261.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10261.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10261.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10261.txt:3', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10261.txt:4', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10272.txt:0', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10272.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10272.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10316.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10316.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10316.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10316.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10355.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10355.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10429.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10429.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10429.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10429.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10449.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10449.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10449.txt:2', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10449.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10467.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10467.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10467.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10467.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10479.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10479.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10479.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10479.txt:3', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1048.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1048.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1048.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10490.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10504.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10504.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10504.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10504.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10532.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10532.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10532.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10570.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10570.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10570.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10570.txt:3', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10570.txt:4', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10579.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10579.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10579.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10579.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10643.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10643.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10643.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10643.txt:3', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10666.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10666.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10666.txt:2', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10668.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10668.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10668.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10677.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10677.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10677.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10677.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10677.txt:4', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10687.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10687.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10687.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10687.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1069.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1069.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1069.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1069.txt:3', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high107.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high107.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high107.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10709.txt:0', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10709.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10709.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10720.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10720.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10720.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10760.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10760.txt:1', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10760.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10771.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10771.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10771.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10775.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10775.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10775.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10788.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10788.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10788.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1080.txt:0', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1080.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1080.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1080.txt:3', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1080.txt:4', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1083.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1083.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1083.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10897.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10897.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10897.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1090.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1090.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1090.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10902.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10902.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10908.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10908.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10908.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10908.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10915.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10915.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10915.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10915.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10944.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10944.txt:1', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10944.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10946.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10946.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10946.txt:2', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high11028.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11028.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11028.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high11031.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11031.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11031.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11036.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11062.txt:0', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11062.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11062.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11062.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11099.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11099.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high11103.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11103.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11103.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11103.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11109.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11109.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11109.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1111.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1111.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1111.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1111.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11112.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high11112.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11112.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11113.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11113.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11129.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11129.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11129.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11129.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11146.txt:0', 'correct': True}]}\n",
      "INFO:task.py:Recovering experiment {'_id': 'Reading Comprehensionhf:bigscience:bloomz-1b1{\"temperature\": 0.01, \"top-p\": 0.5}2023-09-12 10:42:31.073524', 'date': '2023-09-12 10:42:31.073524', 'finished': False, 'too_expensive': False, 'model_id': 'hf:bigscience:bloomz-1b1', 'iterations': 1, 'config': {'temperature': 0.01, 'top-p': 0.5}, 'notes': '', 'task_type': 'Reading Comprehension', 'metrics': {}, 'outputs': [{'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10024.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10024.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10024.txt:2', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10042.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10042.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10042.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10042.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10042.txt:4', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10060.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10060.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10060.txt:2', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10112.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10112.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10112.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10146.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10146.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10146.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10154.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10154.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10154.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10160.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10160.txt:1', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10160.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10177.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10177.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10177.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10179.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10179.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10179.txt:2', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10179.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10187.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10187.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10187.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10215.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10215.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10215.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10229.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10229.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10229.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10255.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10255.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10255.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10261.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10261.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10261.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10261.txt:3', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10261.txt:4', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10272.txt:0', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10272.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10272.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10316.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10316.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10316.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10316.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10355.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10355.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10429.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10429.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10429.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10429.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10449.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10449.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10449.txt:2', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10449.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10467.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10467.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10467.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10467.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10479.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10479.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10479.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10479.txt:3', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1048.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1048.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1048.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10490.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10504.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10504.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10504.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10504.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10532.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10532.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10532.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10570.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10570.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10570.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10570.txt:3', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10570.txt:4', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10579.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10579.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10579.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10579.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10643.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10643.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10643.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10643.txt:3', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10666.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10666.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10666.txt:2', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10668.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10668.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10668.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10677.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10677.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10677.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10677.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10677.txt:4', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10687.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10687.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10687.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10687.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1069.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1069.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1069.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1069.txt:3', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high107.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high107.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high107.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10709.txt:0', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10709.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10709.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10720.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10720.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10720.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10760.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10760.txt:1', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10760.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10771.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10771.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10771.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10775.txt:0', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10775.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10775.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10788.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10788.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10788.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1080.txt:0', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1080.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1080.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high1080.txt:3', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1080.txt:4', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1083.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1083.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1083.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10897.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10897.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10897.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1090.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1090.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1090.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10902.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10902.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10908.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10908.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10908.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10908.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10915.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10915.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10915.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10915.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high10944.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10944.txt:1', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10944.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high10946.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10946.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high10946.txt:2', 'correct': True}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high11028.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11028.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11028.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high11031.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11031.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11031.txt:2', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11036.txt:0', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11062.txt:0', 'correct': True}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11062.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11062.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11062.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11099.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11099.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high11103.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11103.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11103.txt:2', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11103.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11109.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11109.txt:1', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11109.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1111.txt:0', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high1111.txt:1', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1111.txt:2', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high1111.txt:3', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11112.txt:0', 'correct': False}, {'interpreted_output': 'A', 'model_output': ' A', 'input_code': 'RACE:high11112.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11112.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11113.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11113.txt:1', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11129.txt:0', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11129.txt:1', 'correct': True}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11129.txt:2', 'correct': False}, {'interpreted_output': 'D', 'model_output': ' D', 'input_code': 'RACE:high11129.txt:3', 'correct': False}, {'interpreted_output': 'B', 'model_output': ' B', 'input_code': 'RACE:high11146.txt:0', 'correct': True}]}\n",
      "INFO:task.py:Loading RC dataset\n",
      "INFO:task.py:Preparing RC prompts\n",
      "INFO:task.py:Loaded 97487 questions (200 were excluded)\n",
      "INFO:task.py:Cost limit is none\n",
      "INFO:model_runner.py:Running model hf:bigscience:bloomz-1b1\n",
      "INFO:model_runner.py:Counting tokens\n",
      "INFO:model_runner.py:Counting tokens\n",
      "INFO:model_runner.py:Using HF tokenizer for bigscience/bloomz-1b1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\model_running\\test_1.1b_model.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/NewDriveSync/MAGISTR/Diploma/llparison/model_running/test_1.1b_model.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m task\u001b[39m.\u001b[39;49mrun_task(\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/NewDriveSync/MAGISTR/Diploma/llparison/model_running/test_1.1b_model.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   db_connection\u001b[39m=\u001b[39;49mdb,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/NewDriveSync/MAGISTR/Diploma/llparison/model_running/test_1.1b_model.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   date\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(datetime\u001b[39m.\u001b[39;49mdatetime\u001b[39m.\u001b[39;49mnow()),\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/NewDriveSync/MAGISTR/Diploma/llparison/model_running/test_1.1b_model.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   cost_limit\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/NewDriveSync/MAGISTR/Diploma/llparison/model_running/test_1.1b_model.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   db_cache_limit\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/NewDriveSync/MAGISTR/Diploma/llparison/model_running/test_1.1b_model.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[1;32mf:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\model_running\\task.py:383\u001b[0m, in \u001b[0;36mTask.run_task\u001b[1;34m(self, db_connection, date, cost_limit, db_cache_limit)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m TaskType\u001b[39m.\u001b[39mREADING_COMPREHENSION:\n\u001b[0;32m    382\u001b[0m   log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRunning reading comprehension on date \u001b[39m\u001b[39m{\u001b[39;00mdate\u001b[39m}\u001b[39;00m\u001b[39m with cost limit \u001b[39m\u001b[39m{\u001b[39;00mcost_limit\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 383\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_reworked_reading_comprehension(db_connection, date, cost_limit, db_cache_limit\u001b[39m=\u001b[39;49mdb_cache_limit)\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTried running an unsupported task type, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mf:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\model_running\\task.py:285\u001b[0m, in \u001b[0;36mTask.run_reworked_reading_comprehension\u001b[1;34m(self, db_connection, date, cost_limit, db_cache_limit, cost_callback)\u001b[0m\n\u001b[0;32m    276\u001b[0m evaluation_callback \u001b[39m=\u001b[39m EvaluationResultsCallback(\n\u001b[0;32m    277\u001b[0m   db_connection\u001b[39m=\u001b[39mdb_connection,\n\u001b[0;32m    278\u001b[0m   experiment_id\u001b[39m=\u001b[39mexperiment_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m   db_enabled\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    283\u001b[0m   db_cache_limit\u001b[39m=\u001b[39mdb_cache_limit)\n\u001b[0;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 285\u001b[0m   runner\u001b[39m.\u001b[39;49mrun_model(prompts_dict, callback\u001b[39m=\u001b[39;49mevaluation_callback)\n\u001b[0;32m    286\u001b[0m   evaluation_callback\u001b[39m.\u001b[39mfinalize_evaluation()\n\u001b[0;32m    287\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mf:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\model_running\\model_runner.py:142\u001b[0m, in \u001b[0;36mModelRunner.run_model\u001b[1;34m(self, payloads, callback)\u001b[0m\n\u001b[0;32m    139\u001b[0m log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRunning model \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    141\u001b[0m log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCounting tokens\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m payload_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcount_tokens(\u001b[39mlist\u001b[39;49m(payloads\u001b[39m.\u001b[39;49mvalues()))\n\u001b[0;32m    143\u001b[0m log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpayload_size\u001b[39m}\u001b[39;00m\u001b[39m tokens\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39m#if payload_size > self.model.context_size:\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39m#  log.warning(f'Payload size ({payload_size}) > max context size ({self.model.context_size})')\u001b[39;00m\n",
      "File \u001b[1;32mf:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\model_running\\model_runner.py:221\u001b[0m, in \u001b[0;36mModelRunner.count_tokens\u001b[1;34m(self, payloads)\u001b[0m\n\u001b[0;32m    219\u001b[0m   token_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tokenizer\u001b[39m.\u001b[39mencode(payloads))\n\u001b[0;32m    220\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(payloads, \u001b[39mlist\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m   token_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([\u001b[39mlen\u001b[39m(count) \u001b[39mfor\u001b[39;00m count \u001b[39min\u001b[39;00m tokenizer\u001b[39m.\u001b[39;49mencode_batch(payloads)])\n\u001b[0;32m    222\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPayload has unsupported type of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(payloads)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mf:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\model_running\\model_runner.py:211\u001b[0m, in \u001b[0;36mModelRunner.count_tokens.<locals>.<lambda>\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m    209\u001b[0m   log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUsing HF tokenizer for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hf_model_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    210\u001b[0m   tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hf_model_name)\n\u001b[1;32m--> 211\u001b[0m   tokenizer\u001b[39m.\u001b[39mencode_batch \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m texts: [tokenizer\u001b[39m.\u001b[39mencode(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m   DEFAULT_TOKENIZER \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcl100k_base\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mf:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\model_running\\model_runner.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    209\u001b[0m   log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUsing HF tokenizer for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hf_model_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    210\u001b[0m   tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hf_model_name)\n\u001b[1;32m--> 211\u001b[0m   tokenizer\u001b[39m.\u001b[39mencode_batch \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m texts: [tokenizer\u001b[39m.\u001b[39;49mencode(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m   DEFAULT_TOKENIZER \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcl100k_base\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mf:\\venvs\\llparison\\venv\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2373\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m   2336\u001b[0m \u001b[39m@add_end_docstrings\u001b[39m(\n\u001b[0;32m   2337\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[0;32m   2338\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2356\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2357\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mint\u001b[39m]:\n\u001b[0;32m   2358\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2359\u001b[0m \u001b[39m    Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001b[39;00m\n\u001b[0;32m   2360\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2371\u001b[0m \u001b[39m            method).\u001b[39;00m\n\u001b[0;32m   2372\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2373\u001b[0m     encoded_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[0;32m   2374\u001b[0m         text,\n\u001b[0;32m   2375\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   2376\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2377\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2378\u001b[0m         truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   2379\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2380\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2381\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2382\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2383\u001b[0m     )\n\u001b[0;32m   2385\u001b[0m     \u001b[39mreturn\u001b[39;00m encoded_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mf:\\venvs\\llparison\\venv\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2781\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2771\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2772\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2773\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2774\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2778\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2779\u001b[0m )\n\u001b[1;32m-> 2781\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_plus(\n\u001b[0;32m   2782\u001b[0m     text\u001b[39m=\u001b[39mtext,\n\u001b[0;32m   2783\u001b[0m     text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   2784\u001b[0m     add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2785\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2786\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2787\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2788\u001b[0m     stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2789\u001b[0m     is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2790\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2791\u001b[0m     return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2792\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2793\u001b[0m     return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2794\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2795\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2796\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2797\u001b[0m     return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m   2798\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   2799\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2800\u001b[0m )\n",
      "File \u001b[1;32mf:\\venvs\\llparison\\venv\\.venv\\lib\\site-packages\\transformers\\models\\bloom\\tokenization_bloom_fast.py:163\u001b[0m, in \u001b[0;36mBloomTokenizerFast._encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_prefix_space \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_split_into_words):\n\u001b[0;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[0;32m    159\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou need to instantiate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with add_prefix_space=True to use it with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m pretokenized inputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_encode_plus(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\venvs\\llparison\\venv\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:524\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode_plus\u001b[39m(\n\u001b[0;32m    503\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    504\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BatchEncoding:\n\u001b[0;32m    523\u001b[0m     batched_input \u001b[39m=\u001b[39m [(text, text_pair)] \u001b[39mif\u001b[39;00m text_pair \u001b[39melse\u001b[39;00m [text]\n\u001b[1;32m--> 524\u001b[0m     batched_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    525\u001b[0m         batched_input,\n\u001b[0;32m    526\u001b[0m         is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m    527\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m    528\u001b[0m         padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    529\u001b[0m         truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m    530\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m    531\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m    532\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    533\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m    534\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    535\u001b[0m         return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    536\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    537\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    538\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    539\u001b[0m         return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m    540\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    541\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    542\u001b[0m     )\n\u001b[0;32m    544\u001b[0m     \u001b[39m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    545\u001b[0m     \u001b[39m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    546\u001b[0m     \u001b[39mif\u001b[39;00m return_tensors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[1;32mf:\\venvs\\llparison\\venv\\.venv\\lib\\site-packages\\transformers\\models\\bloom\\tokenization_bloom_fast.py:152\u001b[0m, in \u001b[0;36mBloomTokenizerFast._batch_encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_prefix_space \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_split_into_words):\n\u001b[0;32m    147\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou need to instantiate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with add_prefix_space=True to use it with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m pretokenized inputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m     )\n\u001b[1;32m--> 152\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_batch_encode_plus(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\venvs\\llparison\\venv\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:452\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    445\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    446\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    450\u001b[0m )\n\u001b[1;32m--> 452\u001b[0m encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mencode_batch(\n\u001b[0;32m    453\u001b[0m     batch_text_or_text_pairs,\n\u001b[0;32m    454\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    455\u001b[0m     is_pretokenized\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m    456\u001b[0m )\n\u001b[0;32m    458\u001b[0m \u001b[39m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[39m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[39m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[39m#                    ]\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    464\u001b[0m tokens_and_encodings \u001b[39m=\u001b[39m [\n\u001b[0;32m    465\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_encoding(\n\u001b[0;32m    466\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m     \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m encodings\n\u001b[0;32m    476\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task.run_task(\n",
    "  db_connection=db,\n",
    "  date=str(datetime.datetime.now()),\n",
    "  cost_limit=None,\n",
    "  db_cache_limit=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:/NewDriveSync/MAGISTR/Diploma/llparison/.hf/hfmodels/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#t = 'f:/NewDriveSync/MAGISTR/Diploma/llparison' + \n",
    "models_cache = 'f:/NewDriveSync/MAGISTR/Diploma/llparison' + '/.hf/hfmodels/'\n",
    "os.environ['TRANSFORMERS_CACHE'] = models_cache\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\venvs\\llparison\\venv\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\NewDriveSync\\MAGISTR\\Diploma\\llparison\\.hf\\hfmodels\\\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import TextGenerationPipeline \n",
    "import transformers \n",
    "import os\n",
    "import torch\n",
    "\n",
    "#t = 'f:/NewDriveSync/MAGISTR/Diploma/llparison/'\n",
    "models_cache = 'f:\\\\NewDriveSync\\\\MAGISTR\\\\Diploma\\\\llparison' + '\\\\.hf\\\\hfmodels\\\\'\n",
    "idksomeothercache = 'f:\\\\NewDriveSync\\\\MAGISTR\\\\Diploma\\\\llparison' + '\\\\.hf\\\\hfother\\\\'\n",
    "aosdjkasod = 'f:\\\\NewDriveSync\\\\MAGISTR\\\\Diploma\\\\llparison' + '\\\\.hf\\\\whothtefuc\\\\'\n",
    "qqq = 'f:\\\\NewDriveSync\\\\MAGISTR\\\\Diploma\\\\llparison' + '\\\\.hf\\\\qqq\\\\'\n",
    "ooo = 'f:\\\\NewDriveSync\\\\MAGISTR\\\\Diploma\\\\llparison' + '\\\\.hf\\\\ooo\\\\'\n",
    "os.environ['TRANSFORMERS_CACHE'] = models_cache\n",
    "os.environ['HF_DATASETS_CACHE'] = idksomeothercache\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = aosdjkasod\n",
    "os.environ['HF_HOME'] = qqq\n",
    "os.environ['XDG_CACHE_HOME'] = ooo\n",
    "\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))\n",
    "\n",
    "model = \"bigscience/bloomz-1b1\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "#text = 'auwauaua'\n",
    "#tokenizer.encode(text)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Give a generic russian male name: Vladimir Vladimirovich (Russian: Владимир Владимирович) Vladimir Vladimirovich'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    'Give a generic russian male name:',\n",
    "    do_sample=True,\n",
    "    top_k=1,\n",
    "    num_return_sequences=1,\n",
    "    repetition_penalty=1.0,\n",
    "    min_length=30,\n",
    "    max_length=50,\n",
    ")\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\NewDriveSync\\\\MAGISTR\\\\Diploma\\\\llparison\\\\model_running/.hf/hfother/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors:   3%|▎         | 136M/4.40G [00:49<14:49, 4.80MB/s]"
     ]
    }
   ],
   "source": [
    "idksomeothercache = os.getcwd() + '/.hf/hfother/'\n",
    "idksomeothercache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"PY007/TinyLlama-1.1B-step-50K-105b\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"PY007/TinyLlama-1.1B-step-50K-105b\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
